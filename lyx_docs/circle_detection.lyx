#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Cirlce classification for mushroom recognition using artificially generated
 2d samples
\end_layout

\begin_layout Author
Samuel Gelman
\end_layout

\begin_layout Date
3-5-2022
\end_layout

\begin_layout Part*
Motivation
\end_layout

\begin_layout Standard
Mushroom farming is different from traditional plant based agriculture in
 many ways.
 Central of which is that a mushroom is the fruiting body of a fungal organism
 which lives its life underground.
 The organism is composed of a large mycellium network which metabolizes
 decaying organic matter and absorbs water from its growing medium.
\end_layout

\begin_layout Standard
Additonally, fungi do not grow from seeds, rather they are spored from spores
 produced in the mushrooms which are microscopic size.
 
\end_layout

\begin_layout Standard
This anatomy lends a large degree of unpredictability as to where a mushroom
 will sprout from within the growing medium.
 
\end_layout

\begin_layout Standard
The classification of mushrooms via image data will allow the automated
 system to record their location and create a unique profile to track and
 monitor the specific mushroom until it is ready to be harvested and shipped.
 
\end_layout

\begin_layout Standard
The first step is therefore the classification and identification of the
 mushroom.
 This will be done by processing image data gathered from the grow house.
 
\end_layout

\begin_layout Standard
Mushrooms also come in many shapes and sizes.
 some with one cap and some with many.
 Mushroom caps can be light, dark or brightly colored.
 
\end_layout

\begin_layout Standard
Mushrooms can also grow in very dense clusters.
\end_layout

\begin_layout Standard
This makes the task a generalized algorithm a difficult task.
\end_layout

\begin_layout Standard
For this preliminary work, simple types of mushrooms will be attempted for
 verification, namely, mushrooms in which there exist one, spherical body
 which is close to white in color.
 
\end_layout

\begin_layout Standard
This sharp contrast to the dark color of the growing medium will create
 strong gradients in the pixelated data which greatly reduces the difficulty
 of the classification task.
 
\end_layout

\begin_layout Standard
Before actual mushroom image data will be tested, algorithms will be tested
 on simple computer generated sample data.
 This data will be binary and two dimensional.
 
\end_layout

\begin_layout Part*
Method
\end_layout

\begin_layout Section
Data Generation
\end_layout

\begin_layout Standard
As mentioned above, the mushrooms being used are simple white, semi-spherical
 bodies being grown on a dark surface.
 This data can be approximated by creating 2d image samples of white circles
 on a black surface.
 
\end_layout

\begin_layout Standard
A script was written to generate samples of this nature.
 Parameters for the size of the samples, the max/min circle radius and the
 max/min amount of circles to be generated can be entered in the script.
 The script also outputs text files giving the relative paths to the saved
 jpeg images as well as the coordinates for bounding rectangles surrounding
 each of the circles of interest.
 
\end_layout

\begin_layout Standard
A similar script was used to generated randomly placed and sized rectangles
 to provide training data and ensure that the model could distinguish between
 shapes.
 This will help from falsely classifying objects or anomalies in the soil
 that are not mushrooms.
 
\end_layout

\begin_layout Standard
Finally samples with a mixture of circles and squares were generated to
 test the algorithm.
 
\end_layout

\begin_layout Section
Models and Algorithms
\end_layout

\begin_layout Subsection
Haar Cascade
\end_layout

\begin_layout Standard
The training algorithms used were sourced from the open source library for
 computer vision software, OpenCV.
 This is a machine learning algorithm which is given positive and negative
 image data and classifiers are trained through this supervised learning
 process.
 Positive images are images where the object we wish to train the algorithm
 to detect is present while negative images are any other image.
\end_layout

\begin_layout Standard
The Haar cascade algorithm works by using an number of filters to scan an
 input image and generate corresponding feature maps.
 
\end_layout

\begin_layout Standard
At first, each individual feature extracted is known as a 
\begin_inset Quotes eld
\end_inset

weak feature
\begin_inset Quotes erd
\end_inset

.
 After many samples are run through the classifier cascade, these 
\begin_inset Quotes eld
\end_inset

weak classifiers
\begin_inset Quotes erd
\end_inset

 are combined to create strong classifiers which lend a higher confidence
 rating towards classifying the object of interest.
\end_layout

\begin_layout Subsection
Circle Hough Transform
\end_layout

\begin_layout Standard
The circle Hough Transform is a feature extraction technique used for image
 processing tasks.
 
\end_layout

\begin_layout Standard
To explain the theory we start with a the mathematical description of the
 circle in two-dimensional space using Cartesian coordinates:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left(x-a\right)^{2}+\left(y-b\right)^{2}=r^{2}.
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 represent the x and y coordinates to the center of the circle respectively
 and 
\begin_inset Formula $r$
\end_inset

 is the circles radius.
 
\end_layout

\begin_layout Standard
When the radius is fixed, this equation defines the outline of a circle.
 In the event that our image data has circles which are filled in, the edges
 can be extracted using the Canny edge detector algorithm.
 This is a preliminary data preparation step built into the openCV implementatio
n of the algorithm.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/sammy/mushrooms/saved_imgs/the-circular-Hough-transform.png
	scale 50
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
The circular Hough transform maps points from (x,y) space over to the (a,b)
 parameter space.
 For each point in parameter space the corresponding circles are drawn and
 recorded in the accumulator marix as seen by the dotted lines.
 The maximum marks the center of the circle marked by the blue point.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The Hough transform works by scanning over all the x-y coordinates of the
 edges in the input image and tracing out a circle in the parameter space.
 When only a single radius is being scanned for then the parameter space
 is two dimensional, namely 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 of which we are mapping the output to is the given values for the center
 of the circle given the edge points represented by x and y.
 This can be seen in Figure 1.
 The output of each of these scans is recorded into an accumulator matrix
 which is the same size as the sample image.
 
\end_layout

\begin_layout Standard
The maxima points in the accumulator matrix after all the edges have been
 scanned will represent the center of the circles present in the input image.
 
\end_layout

\begin_layout Standard
If the radius of the circle is unknown the parameter space inherits another
 dimension or 
\begin_inset Formula $r$
\end_inset

.
 
\end_layout

\begin_layout Standard
This algorithm has several downsides and room for optimizations.
 
\end_layout

\begin_layout Standard
For one, the parameter space that we are accumulating to is a discrete represent
ation of space.
 So choosing the resolution of the accumulator is a tunable hyper-parameter.
 
\end_layout

\begin_layout Standard
In addition, in real life examples, circles are not perfect, in this way
 several circles of the same size can have differing maxima in the accumulator
 matrix after the algorithm has finished its scan.
 For this reason a threshold parameter is necessary to determine which candidate
 circles are accepted.
 
\end_layout

\begin_layout Standard
Deep neural networks have been shown to outperform the Hough Transform and
 are less susceptible to many of the potential false classifications inherent
 in the method.
 
\end_layout

\begin_layout Standard
Despite all of these potential drawback the algorithm is both powerful,
 simple and widely applied.
 
\end_layout

\begin_layout Part*
Results
\end_layout

\begin_layout Section
Analytical Review
\end_layout

\begin_layout Subsection
Haar Cascade
\end_layout

\begin_layout Standard
The first algorithm tested was the Haar Cascade classifier.
 While this model worked well at identifying shapes, it failed to distinguish
 between the circles and rectangles.
 This led to an extremely high 
\begin_inset Quotes eld
\end_inset

false alarm
\begin_inset Quotes erd
\end_inset

 rate.
 After further research, the inability for Haar cascade classifiers to distingui
sh between the soft edges of circles and the edges of squares was a known
 problem.
 The Haar Cascade was implemented successfully from a data preparation stand
 point but the inability to detect the soft edges made the model unable
 to distinguish between the squares and circles.
 
\end_layout

\begin_layout Standard
So while the algorithm managed to detect the correct number of objects it
 proved to be a poor choice for the purposes of this project.
 
\end_layout

\begin_layout Subsection
Circle Hough Transform
\end_layout

\begin_layout Standard
While needing some tinkering with respect to the parameters, the Hough Transform
 proved to be very effective while remaining relatively easy to implement.
\end_layout

\begin_layout Standard
Some optimization was needed, but a final accuracy of ~99.583 percent was
 reach.
 This value was determined by generating 1000 samples of size 500x500.
 Anywhere from one to twelve shapes were generated onto the images with
 a 75% chance of it being a circle and a 25% chance of it being a rectangle.
 The maximum radius or length/width of the shapes were 40 pixels while the
 minimum was 15 pixels.
\end_layout

\begin_layout Standard
The algorithm counted the number of circles found and compared this to the
 number of circles present.
 For each sample the absolute value of the difference was collected and
 summed.
 At the end, the amount of missed circles and false negatives were compared
 to the total number of circles accurately identified.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../saved_imgs/classifier_example_img.png
	scale 30
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Image sample before and after Hough transform.
 Information of the circles is stored as a three dimensional coordinate
 of (x_center, y_center, radius)
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This metric does have a pitfall in that samples where there is both a false
 positive and a missed circle get recorded as having no errors.
 This phenomena was observed when scanning through the data but it was rare.
 For a production grade algorithm a more rigorous score would be formulated,
 but to present a rough sketch of the capabilities of this algorithm this
 metric felt sufficient.
 
\end_layout

\begin_layout Standard
Another important parameter which was tuned is setting the max radius for
 circles which the Hough transform can identify.
 This was set to one fourth of the image size which was 125 pixels.
 This is over triple the max radius of the mushroom.
 By lowering this down to 80 pixels, twice the size, the accuracy was increased
 to ~99.815.
\end_layout

\begin_layout Standard
All other parameters of the algorithm were taken via online recommendations
 and trial and error.
 
\end_layout

\begin_layout Part*
Conclusion
\end_layout

\begin_layout Standard
With only reasonable effort and through utilizing open source technologies,
 a frame work for data generation and circle classification was completed
 with a fairly high confidence rating.
 While better algorithms exist, the circle Hough transform worked fast and
 well.
 While real world image data is always more complicated to work with, it
 seems more than plausible that the working implementation of the Hough
 transform here could preform the task of finding mushrooms growing on a
 2d grow bed.
 
\end_layout

\begin_layout Standard
Thank you for taking the time to read this report.
 
\end_layout

\begin_layout Standard
All code written is available on my github upon request.
 
\end_layout

\begin_layout Right Address
*SammyGelman@gmail.com, github: sammygelman
\end_layout

\end_body
\end_document
